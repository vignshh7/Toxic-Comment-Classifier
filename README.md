# ğŸ¤– DeepToxicDetector â€“ Toxic Comment Classifier Using Deep Learning

This project focuses on detecting **toxic language** in user-generated content (e.g., YouTube, Reddit) using **deep learning models**. The classifier labels text across multiple categories like `toxic`, `obscene`, `insult`, `threat`, and more. It is trained on the [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge) dataset.

---

## ğŸ“Œ Features

- ğŸ“š **Multi-label Classification**: Each comment can have multiple toxicity labels
- ğŸ§  **Deep Learning Models**: LSTM, Bi-LSTM, and CNN architectures implemented
- ğŸ—£ï¸ **Word Embeddings**: Pre-trained GloVe embeddings used for semantic understanding
- ğŸ“Š **Evaluation**: Precision, Recall, F1-Score across all six labels
- ğŸ§ª **Experimental Setup**: Dropout tuning, Batch Size experimentation
- ğŸ“¥ **CLI-based Testing**: Interactive script to test sample comments (`toxicom.py`)

---

## ğŸ” Toxicity Categories

| Label            | Description                         |
|------------------|-------------------------------------|
| `toxic`          | General toxicity                    |
| `severe_toxic`   | Extremely rude or hateful           |
| `obscene`        | Offensive or lewd language          |
| `threat`         | Threatening violence                |
| `insult`         | Personal insults or attacks         |
| `identity_hate`  | Hate speech targeting identity      |

---


## âš™ï¸ Training Configuration

- **Tokenizer**: Keras Tokenizer
- **Embeddings**: 100D GloVe word vectors
- **Vocabulary Size**: 50,000 words
- **Max Sequence Length**: 200 tokens
- **Model Architecture**: Bidirectional LSTM with 2 hidden layers and dropout
- **Loss Function**: Binary Crossentropy
- **Optimizer**: Adam optimizer
- **Batch Size**: 128
- **Epochs**: 10

---

## ğŸ“Š Model Performance

### F1-Scores by Category

| Category       | F1-Score | Precision | Recall |
|----------------|----------|-----------|--------|
| Toxic          | 0.89     | 0.91      | 0.87   |
| Obscene        | 0.88     | 0.90      | 0.86   |
| Insult         | 0.85     | 0.87      | 0.83   |
| Severe Toxic   | 0.74     | 0.76      | 0.72   |
| Identity Hate  | 0.72     | 0.74      | 0.70   |
| Threat         | 0.68     | 0.71      | 0.65   |

### Overall Metrics
- **Average F1-Score**: 0.79
- **Training Accuracy**: 95.2%
- **Validation Accuracy**: 92.8%

---



## ğŸ“ˆ Model Architecture

```
Input Layer (200,)
    â†“
Embedding Layer (50000, 100)
    â†“
Bidirectional LSTM (64 units)
    â†“
Dropout (0.3)
    â†“
Bidirectional LSTM (32 units)
    â†“
Dropout (0.3)
    â†“
Dense Layer (6 units, sigmoid activation)
```

---

## ğŸ§ª Experimental Results

### Hyperparameter Tuning
- **Dropout Rate**: Tested 0.2, 0.3, 0.5 â†’ Best: 0.3
- **LSTM Units**: Tested 32, 64, 128 â†’ Best: 64
- **Batch Size**: Tested 64, 128, 256 â†’ Best: 128
- **Learning Rate**: Tested 0.001, 0.01 â†’ Best: 0.001

### Data Distribution
- **Total Comments**: 159,571
- **Toxic Comments**: 15,294 (9.6%)
- **Clean Comments**: 144,277 (90.4%)

---

## ğŸ”® Future Enhancements

- ğŸš€ **Web Deployment**: Deploy as a Streamlit or Flask web application
- ğŸ¤– **Advanced Models**: Fine-tune with BERT, RoBERTa, or DistilBERT
- ğŸŒ **Multilingual Support**: Handle code-mixed and multilingual comments
- âš¡ **Real-time Processing**: Apply to live chat moderation systems
- ğŸ“± **API Integration**: RESTful API for third-party applications
- ğŸ” **Explainability**: Add LIME/SHAP for model interpretability

---

## ğŸ“‹ Requirements

```
tensorflow>=2.8.0
keras>=2.8.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0
nltk>=3.7
```

---

## ğŸ“ Dataset Information

The model is trained on the **Jigsaw Toxic Comment Classification Challenge** dataset, which contains:
- **159,571** Wikipedia comments
- **6 toxicity labels** (multi-label classification)
- **Human-annotated** ground truth labels
- **Imbalanced dataset** with class weighting applied

---


## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).  
You are free to use, modify, and distribute this software with proper attribution.

---

## ğŸ™‹â€â™‚ï¸ About the Author

@vignshh7

**Connect with me:**
- ğŸ“§ Email: your.email@example.com
- ğŸ’¼ LinkedIn: [Your LinkedIn Profile]
- ğŸ± GitHub: [Your GitHub Profile]

---

## ğŸ™ Acknowledgments

- **Jigsaw/Conversation AI** for providing the dataset
- **Stanford NLP Group** for GloVe word embeddings
- **Kaggle Community** for insights and discussions
- **TensorFlow/Keras** team for the deep learning framework

---

## â­ Star History

If you found this project helpful, please consider giving it a star! â­

---

*Feel free to explore, fork, and reuse parts of this repository for learning and research purposes.*
